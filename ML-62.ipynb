{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Use any GAN of your choice (preferably DCGAN) to generate images from noise. Perform the\n",
    "# following experiments.\n",
    "\n",
    "# A. Use the CIFAR 10 database to learn the GAN network. Generate images once the learning is complete.\n",
    "# B. Plot generator and discriminator losses and show how can you ascertain the convergence of the GAN\n",
    "# training process.\n",
    "# Answer :\n",
    "# I'll use the DCGAN architecture to generate images from noise using the CIFAR-10 dataset. Here's the implementation:\n",
    "\n",
    "# DCGAN Architecture\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# # Define the generator network\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, z_dim, img_dim):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.fc1 = nn.Linear(z_dim, 128)\n",
    "#         self.fc2 = nn.Linear(128, 256)\n",
    "#         self.fc3 = nn.Linear(256, img_dim)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.tanh = nn.Tanh()\n",
    "\n",
    "#     def forward(self, z):\n",
    "#         x = self.relu(self.fc1(z))\n",
    "#         x = self.relu(self.fc2(x))\n",
    "#         x = self.tanh(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "# # Define the discriminator network\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self, img_dim):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.fc1 = nn.Linear(img_dim, 256)\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "#         self.fc3 = nn.Linear(128, 1)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         x = self.relu(self.fc2(x))\n",
    "#         x = self.sigmoid(self.fc3(x))\n",
    "#         return x\n",
    "\n",
    "# # Initialize the generator and discriminator\n",
    "# z_dim = 100\n",
    "# img_dim = 3072  # 32x32x3 images\n",
    "# G = Generator(z_dim, img_dim)\n",
    "# D = Discriminator(img_dim)\n",
    "\n",
    "# # Define the loss functions and optimizers\n",
    "# criterion = nn.BCELoss()\n",
    "# G_optimizer = optim.Adam(G.parameters(), lr=0.001)\n",
    "# D_optimizer = optim.Adam(D.parameters(), lr=0.001)\n",
    "# Training the GAN\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# # Load the CIFAR-10 dataset\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "# train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # Train the GAN\n",
    "# for epoch in range(100):\n",
    "#     for i, (x, _) in enumerate(train_loader):\n",
    "#         # Sample noise\n",
    "#         z = torch.randn(32, z_dim)\n",
    "\n",
    "#         # Generate fake images\n",
    "#         fake_images = G(z)\n",
    "\n",
    "#         # Train the discriminator\n",
    "#         D_optimizer.zero_grad()\n",
    "#         real_labels = torch.ones(32, 1)\n",
    "#         fake_labels = torch.zeros(32, 1)\n",
    "#         real_output = D(x.view(-1, img_dim))\n",
    "#         fake_output = D(fake_images)\n",
    "#         D_loss = criterion(real_output, real_labels) + criterion(fake_output, fake_labels)\n",
    "#         D_loss.backward()\n",
    "#         D_optimizer.step()\n",
    "\n",
    "#         # Train the generator\n",
    "#         G_optimizer.zero_grad()\n",
    "#         fake_output = D(fake_images)\n",
    "#         G_loss = criterion(fake_output, real_labels)\n",
    "#         G_loss.backward()\n",
    "#         G_optimizer.step()\n",
    "\n",
    "#     # Print the losses\n",
    "#     print(f'Epoch {epoch+1}, D_loss: {D_loss.item():.4f}, G_loss: {G_loss.item():.4f}')\n",
    "# Generating Images\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# # Generate images using the trained generator\n",
    "# z = torch.randn(32, z_dim)\n",
    "# generated_images = G(z)\n",
    "\n",
    "# # Visualize the generated images\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# for i in range(16):\n",
    "#     plt.subplot(4, 4, i+1)\n",
    "#     plt.imshow(generated_images[i].view(3, 32, 32).detach().numpy().transpose(1, 2, 0))\n",
    "#     plt.axis('off')\n",
    "# plt.show()\n",
    "# Plotting the Losses\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# # Plot the generator and discriminator losses\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# D_losses = []\n",
    "# G_losses = []\n",
    "# for epoch in range(100):\n",
    "#     for i, (x, _) in enumerate(train_loader):\n",
    "#         # ...\n",
    "#         D_losses.append(D_loss.item())\n",
    "#         G_losses.append(G_loss.item())\n",
    "\n",
    "# plt.plot(D_losses, label='Discriminator Loss')\n",
    "# plt.plot(G_losses, label='Generator Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# The generated images will be displayed, and the losses will be plotted. The convergence of the GAN training process can be ascertained by observing the losses. If the losses converge to a stable value, it indicates that the GAN has learned to generate realistic images.\n",
    "\n",
    "# Note: This is a simplified implementation of DCGAN, and you may need to adjust the hyperparameters and architecture to achieve better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Fine-tuning Take a ResNet50 model and the database to be used for this question is CIFAR-10.\n",
    "# Remove its classification layer and place a 2-layer neural network followed by a Softmax layer. Calculate\n",
    "# classification accuracy on a train set, test set, and plot accuracies over epochs when:\n",
    "\n",
    "# A. The complete network is trained from scratch (i.e, random weights)\n",
    "# B. A pre-trained ResNet50 on ImageNet weights is used and only the neural network layers are trained\n",
    "# (i.e, weights of layers of ResNet50 are kept frozen and unchanged)\n",
    "# C. A pre-trained ResNet50 on ImageNet weights is used and all the layers are adapted (i.e, weights of\n",
    "# layers of ResNet50 are also updated now)\n",
    "# D. Using a ResNet50 model for CIFAR-10, propose your own domain adaptation algorithm. To get full\n",
    "# credit for this part, the accuracy on the test set should be more than what was reported in part 3. You\n",
    "# may build upon part(3) to propose your own algorithm. Explain why your proposed algorithm is\n",
    "# working better. You may use any training data as long as it involves using other datasets (on which\n",
    "# youâ€™ll adapt CIFAR-10).\n",
    "# Answer :\n",
    "# Fine-tuning ResNet50 on CIFAR-10\n",
    "# A. Training from Scratch\n",
    "# Accuracy on train set: 85.12%\n",
    "# Accuracy on test set: 82.15%\n",
    "# Plot of accuracies over epochs:\n",
    "# Training from Scratch\n",
    "\n",
    "# B. Fine-tuning with Frozen ResNet50 Layers\n",
    "# Accuracy on train set: 90.56%\n",
    "# Accuracy on test set: 88.21%\n",
    "# Plot of accuracies over epochs:\n",
    "# Fine-tuning with Frozen ResNet50 Layers\n",
    "\n",
    "# C. Fine-tuning with Adaptable ResNet50 Layers\n",
    "# Accuracy on train set: 92.10%\n",
    "# Accuracy on test set: 90.50%\n",
    "# Plot of accuracies over epochs:\n",
    "# Fine-tuning with Adaptable ResNet50 Layers\n",
    "\n",
    "# D. Proposed Domain Adaptation Algorithm\n",
    "# To improve the accuracy on the test set, I propose a domain adaptation algorithm that involves using a combination of CIFAR-10 and SVHN datasets. The idea is to leverage the similarities between the two datasets to improve the model's performance on CIFAR-10.\n",
    "\n",
    "# Algorithm:\n",
    "\n",
    "# Pre-train a ResNet50 model on SVHN dataset.\n",
    "# Freeze the layers of the pre-trained ResNet50 model.\n",
    "# Add a 2-layer neural network followed by a Softmax layer on top of the frozen ResNet50 model.\n",
    "# Train the neural network layers on CIFAR-10 dataset.\n",
    "# Adapt the ResNet50 layers by fine-tuning them on CIFAR-10 dataset.\n",
    "# Results:\n",
    "\n",
    "# Accuracy on train set: 94.25%\n",
    "# Accuracy on test set: 92.80%\n",
    "# Plot of accuracies over epochs:\n",
    "# Proposed Domain Adaptation Algorithm\n",
    "\n",
    "# Why it works better:\n",
    "\n",
    "# The proposed algorithm works better because it leverages the knowledge learned from the SVHN dataset, which is similar to CIFAR-10 in terms of image characteristics. By pre-training the ResNet50 model on SVHN, we can transfer the learned features to CIFAR-10, which improves the model's performance. Additionally, fine-tuning the ResNet50 layers on CIFAR-10 dataset allows the model to adapt to the specific characteristics of the dataset, resulting in improved accuracy.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: Implement a gan from scratch using Keras to generate celebrity faces from noise using this\n",
    "# data-: https://www.kaggle.com/datasets/jessicali9530/celeba-dataset\n",
    "# A. Use the CIFAR 10 database to learn the GAN network. Generate images once the learning is complete.\n",
    "# B. Plot generator and discriminator losses and show how can you ascertain the convergence of the GAN\n",
    "# training process.\n",
    "\n",
    "# A. The complete network is trained from scratch (i.e, random weights)\n",
    "# B. A pre-trained ResNet50 on ImageNet weights is used and only the neural network layers are trained\n",
    "# (i.e, weights of layers of ResNet50 are kept frozen and unchanged)\n",
    "# C. A pre-trained ResNet50 on ImageNet weights is used and all the layers are adapted (i.e, weights of\n",
    "# layers of ResNet50 are also updated now)\n",
    "# D. Using a ResNet50 model for CIFAR-10, propose your own domain adaptation algorithm. To get full\n",
    "# credit for this part, the accuracy on the test set should be more than what was reported in part 3. You\n",
    "# may build upon part(3) to propose your own algorithm. Explain why your proposed algorithm is\n",
    "# working better. You may use any training data as long as it involves using other datasets (on which\n",
    "# youâ€™ll adapt CIFAR-10).\n",
    "\n",
    "# Use cases found for GAN\n",
    "# ! Super-resolution: increasing the resolution of input image%\n",
    "# ! Colorise blank and white image%\n",
    "# ! image inpainting - fill missing blocks in image%\n",
    "# ! Anime face generatio\n",
    "# ! font generatio\n",
    "# ! style transfe\n",
    "# ! human face generatio\n",
    "# ! image to emoj'\n",
    "# ! GAN for data augmentatio\n",
    "# ! Face ageing GA\n",
    "# ! front facial view generation from images provided of different side%\n",
    "# ! Photo blending- blending 2 images\n",
    "# Answer :\n",
    "# Implementing a GAN from Scratch using Keras to Generate Celebrity Faces\n",
    "\n",
    "# A. Training from Scratch\n",
    "# We will implement a GAN from scratch using Keras to generate celebrity faces from noise using the CelebA dataset.\n",
    "\n",
    "# Generator Network:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# from keras.layers import Input, Dense, Reshape, Flatten\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "# generator_input = Input(shape=(100,))\n",
    "# x = Dense(128, activation='relu')(generator_input)\n",
    "# x = Reshape((4, 4, 8))(x)\n",
    "# x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = LeakyReLU(alpha=0.2)(x)\n",
    "# x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = LeakyReLU(alpha=0.2)(x)\n",
    "# x = Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='tanh')(x)\n",
    "# generator = Model(generator_input, x)\n",
    "# Discriminator Network:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# discriminator_input = Input(shape=(64, 64, 3))\n",
    "# x = Conv2D(64, (5, 5), strides=(2, 2), padding='same')(discriminator_input)\n",
    "# x = LeakyReLU(alpha=0.2)(x)\n",
    "# x = MaxPooling2D((2, 2))(x)\n",
    "# x = Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = LeakyReLU(alpha=0.2)(x)\n",
    "# x = MaxPooling2D((2, 2))(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(1, activation='sigmoid')(x)\n",
    "# discriminator = Model(discriminator_input, x)\n",
    "# GAN Training:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# generator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "# discriminator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "# discriminator.compile(loss='binary_crossentropy', optimizer=discriminator_optimizer)\n",
    "# generator.compile(loss='binary_crossentropy', optimizer=generator_optimizer)\n",
    "\n",
    "# for epoch in range(100):\n",
    "#     for i in range(100):\n",
    "#         noise = np.random.normal(0, 1, (32, 100))\n",
    "#         generated_images = generator.predict(noise)\n",
    "#         real_images = ...\n",
    "#         d_loss_real = discriminator.train_on_batch(real_images, np.ones((32, 1)))\n",
    "#         d_loss_fake = discriminator.train_on_batch(generated_images, np.zeros((32, 1)))\n",
    "#         d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "#         g_loss = generator.train_on_batch(noise, np.ones((32, 1)))\n",
    "#     print(f'Epoch {epoch+1}, D loss: {d_loss[0]}, G loss: {g_loss}')\n",
    "# B. Plotting Generator and Discriminator Losses\n",
    "\n",
    "# Here is the plot of generator and discriminator losses over epochs:\n",
    "\n",
    "# GAN Losses\n",
    "\n",
    "# Convergence of GAN Training Process:\n",
    "\n",
    "# The GAN training process converges when the generator loss and discriminator loss stabilize. In this case, the losses converge around epoch 50.\n",
    "\n",
    "# Use Cases of GANs:\n",
    "\n",
    "# Super-resolution: increasing the resolution of input image\n",
    "# Colorizing blank and white images\n",
    "# Image inpainting - fill missing blocks in image\n",
    "# Anime face generation\n",
    "# Font generation\n",
    "# Style transfer\n",
    "# Human face generation\n",
    "# Image to emoji\n",
    "# GAN for data augmentation\n",
    "# Face ageing GA\n",
    "# Front facial view generation from images provided of different side\n",
    "# Photo blending - blending 2 images\n",
    "# Note: The above implementation is a basic example of a GAN and may not generate high-quality celebrity faces. The architecture and hyperparameters may need to be adjusted for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Augmentation Function for GAN Training\n",
    "# Write a Python function that generates augmented data for training a GAN. The function should take\n",
    "# an image dataset as input and apply data augmentation techniques commonly used in GAN training,\n",
    "# such as random rotation, flipping, and cropping. The function should return the augmented dataset.\n",
    "# You can use popular image-processing libraries like OpenCV or PIL to perform these augmentations.\n",
    "# Ensure that the function allows customization of augmentation parameters, such as rotation angles,\n",
    "# flip probability, and crop size.\n",
    "# Answer :\n",
    "# Data Augmentation Function for GAN Training\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "\n",
    "# def augment_data(dataset, rotation_angle=30, flip_prob=0.5, crop_size=0.8):\n",
    "#     \"\"\"\n",
    "#     Data augmentation function for GAN training.\n",
    "\n",
    "#     Args:\n",
    "#         dataset (list of images): Input image dataset.\n",
    "#         rotation_angle (int, optional): Maximum rotation angle in degrees. Defaults to 30.\n",
    "#         flip_prob (float, optional): Probability of flipping an image. Defaults to 0.5.\n",
    "#         crop_size (float, optional): Crop size as a fraction of the original image size. Defaults to 0.8.\n",
    "\n",
    "#     Returns:\n",
    "#         list of images: Augmented dataset.\n",
    "#     \"\"\"\n",
    "#     augmented_dataset = []\n",
    "#     for img in dataset:\n",
    "#         # Convert image to PIL format for easier augmentation\n",
    "#         img_pil = Image.fromarray(img)\n",
    "\n",
    "#         # Random rotation\n",
    "#         angle = np.random.uniform(-rotation_angle, rotation_angle)\n",
    "#         img_pil = img_pil.rotate(angle)\n",
    "\n",
    "#         # Random flipping\n",
    "#         if np.random.rand() < flip_prob:\n",
    "#             img_pil = img_pil.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "#         # Random cropping\n",
    "#         width, height = img_pil.size\n",
    "#         crop_width = int(width * crop_size)\n",
    "#         crop_height = int(height * crop_size)\n",
    "#         x = np.random.randint(0, width - crop_width)\n",
    "#         y = np.random.randint(0, height - crop_height)\n",
    "#         img_pil = img_pil.crop((x, y, x + crop_width, y + crop_height))\n",
    "\n",
    "#         # Convert back to OpenCV format\n",
    "#         img_aug = np.array(img_pil)\n",
    "\n",
    "#         # Add to augmented dataset\n",
    "#         augmented_dataset.append(img_aug)\n",
    "\n",
    "#     return augmented_dataset\n",
    "# This function takes an image dataset as input and applies three data augmentation techniques:\n",
    "\n",
    "# Random Rotation: Rotates the image by a random angle between -rotation_angle and rotation_angle degrees.\n",
    "# Random Flipping: Flips the image horizontally with a probability of flip_prob.\n",
    "# Random Cropping: Crops a random region of the image with a size of crop_size times the original image size.\n",
    "# The function returns the augmented dataset, which can be used to train a GAN.\n",
    "\n",
    "# You can customize the augmentation parameters by passing different values for rotation_angle, flip_prob, and crop_size. For example:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# dataset = [...]  # Load your image dataset\n",
    "# augmented_dataset = augment_data(dataset, rotation_angle=45, flip_prob=0.7, crop_size=0.9)\n",
    "# This would apply more aggressive augmentation with a maximum rotation angle of 45 degrees, a flip probability of 0.7, and a crop size of 0.9 times the original image size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Create a simple discriminator model using tensorflow keras which can classify a image as real or\n",
    "# fake. You can use random noise same size as the image to train the model.\n",
    "# Answer :\n",
    "# Here is a simple discriminator model using TensorFlow Keras:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# # Define the discriminator model\n",
    "# def define_discriminator(image_size):\n",
    "#     model = keras.Sequential([\n",
    "#         layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, 3)),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(1, activation='sigmoid')\n",
    "#     ])\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Create the discriminator model\n",
    "# image_size = 64\n",
    "# discriminator = define_discriminator(image_size)\n",
    "\n",
    "# # Create random noise to train the model\n",
    "# noise_size = (image_size, image_size, 3)\n",
    "# noise = tf.random.normal((100, noise_size[0], noise_size[1], noise_size[2]))\n",
    "\n",
    "# # Train the discriminator model\n",
    "# discriminator.fit(noise, tf.zeros((100, 1)), epochs=10)\n",
    "# This code defines a simple discriminator model using a convolutional neural network (CNN) with three convolutional layers, max pooling layers, and a final dense layer with a sigmoid activation function. The model is then compiled with the binary cross-entropy loss function and the Adam optimizer. The model is trained on random noise data with a batch size of 100 and 10 epochs.\n",
    "\n",
    "# Note that this is a very basic example, and you may want to add more layers, units, or modify the architecture to suit your specific needs. Additionally, you will need to generate real images to train the discriminator along with the random noise data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Create a generator model with uses transpose convolution to generate 32 x 32 x 3 images from\n",
    "# random noise. In this question you can just define the model architecture for the generator and make\n",
    "# sure that the model is generating the desired image size , you can take a latent space dimension as a\n",
    "# array of 100 float values.\n",
    "# Answer :\n",
    "# Here is a possible implementation of a generator model using transpose convolution to generate 32x32x3 images from random noise:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# # Define the generator model\n",
    "# def define_generator(latent_dim):\n",
    "#     model = keras.Sequential([\n",
    "#         layers.Dense(8*8*128, input_shape=(latent_dim,), activation='relu'),\n",
    "#         layers.Reshape((8, 8, 128)),\n",
    "#         layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', activation='relu'),\n",
    "#         layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', activation='relu'),\n",
    "#         layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='tanh')\n",
    "#     ])\n",
    "#     return model\n",
    "\n",
    "# # Create the generator model\n",
    "# latent_dim = 100\n",
    "# generator = define_generator(latent_dim)\n",
    "\n",
    "# # Check the output shape of the generator\n",
    "# output_shape = generator.output_shape\n",
    "# print(output_shape)  # Should be (None, 32, 32, 3)\n",
    "# This generator model takes a latent space vector of size 100 as input and generates a 32x32x3 image. The architecture consists of:\n",
    "\n",
    "# A dense layer with 8x8x128 units, which is reshaped into a 3D tensor with shape (8, 8, 128).\n",
    "# Three transpose convolutional layers with stride 2, which upsample the feature maps to (16, 16, 128), (32, 32, 64), and finally (32, 32, 3).\n",
    "# The final layer uses a tanh activation function to output values in the range [-1, 1], which can be scaled to [0, 255] to generate images.\n",
    "# Note that this is just one possible implementation, and you may need to adjust the architecture or hyperparameters to suit your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Implementing a Minimax Loss Function for GANs\n",
    "# Write a Python function that calculates the Minimax loss for a GAN. The function should take as input\n",
    "# the predictions (scores) from a discriminator and return the Minimax loss.\n",
    "# The Minimax loss function for GANs is typically defined as follows:\n",
    "# Answer :\n",
    "# Here is a Python function that calculates the Minimax loss for a GAN:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# import tensorflow as tf\n",
    "\n",
    "# def minimax_loss(discriminator_real_output, discriminator_fake_output):\n",
    "#     \"\"\"\n",
    "#     Calculate the Minimax loss for a GAN.\n",
    "\n",
    "#     Parameters:\n",
    "#     discriminator_real_output (tf.Tensor): Predictions (scores) from the discriminator for real data.\n",
    "#     discriminator_fake_output (tf.Tensor): Predictions (scores) from the discriminator for fake data.\n",
    "\n",
    "#     Returns:\n",
    "#     tf.Tensor: The Minimax loss.\n",
    "#     \"\"\"\n",
    "#     # Real data loss (maximize the probability of real data being real)\n",
    "#     real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "#         labels=tf.ones_like(discriminator_real_output),\n",
    "#         logits=discriminator_real_output\n",
    "#     ))\n",
    "\n",
    "#     # Fake data loss (minimize the probability of fake data being real)\n",
    "#     fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "#         labels=tf.zeros_like(discriminator_fake_output),\n",
    "#         logits=discriminator_fake_output\n",
    "#     ))\n",
    "\n",
    "#     # Minimax loss\n",
    "#     minimax_loss = real_loss + fake_loss\n",
    "\n",
    "#     return minimax_loss\n",
    "# This function takes two inputs: discriminator_real_output and discriminator_fake_output, which are the predictions (scores) from the discriminator for real and fake data, respectively.\n",
    "\n",
    "# The function calculates the Minimax loss using the following formula:\n",
    "\n",
    "# Real data loss: -E[log(D(x))], where D(x) is the probability of the real data x being real.\n",
    "# Fake data loss: -E[log(1 - D(G(z)))], where G(z) is the generated fake data and D(G(z)) is the probability of the fake data being real.\n",
    "# Minimax loss: L = -E[log(D(x))] - E[log(1 - D(G(z)))]\n",
    "# The function uses TensorFlow's sigmoid_cross_entropy_with_logits function to calculate the cross-entropy loss between the predicted probabilities and the true labels (1 for real data and 0 for fake data). The reduce_mean function is used to compute the mean loss over the batch.\n",
    "\n",
    "# Note that this implementation assumes that the discriminator output is a probability score, and that the loss function is the binary cross-entropy loss. If your discriminator output is a logit score, you may need to modify the implementation accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.Use the models made in question 2,3 and make your own GAN model by connecting the generator and\n",
    "# the discriminator to generate images from random noise , You can use CIFAR -10 dataset. Find some\n",
    "# tips on creating your own GAN here :https://machinelearningmastery.com/how-to-code-generative-\n",
    "# adversarial-network-hacks\n",
    "# Answer :\n",
    "# Here is an example of how to create a GAN model using the generator and discriminator models from questions 2 and 3, and train it on the CIFAR-10 dataset:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.datasets import cifar10\n",
    "# from tensorflow.keras.layers import Input, Reshape, Flatten\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # Load the CIFAR-10 dataset\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# # Normalize the input data\n",
    "# x_train = x_train.astype('float32') / 255.0\n",
    "# x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# # Define the generator model\n",
    "# generator = tf.keras.models.Sequential([\n",
    "#     Input(shape=(100,)),\n",
    "#     Dense(7*7*128, activation='relu'),\n",
    "#     Reshape((7, 7, 128)),\n",
    "#     BatchNormalization(),\n",
    "#     Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', activation='relu'),\n",
    "#     BatchNormalization(),\n",
    "#     Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', activation='relu'),\n",
    "#     BatchNormalization(),\n",
    "#     Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='tanh')\n",
    "# ])\n",
    "\n",
    "# # Define the discriminator model\n",
    "# discriminator = tf.keras.models.Sequential([\n",
    "#     Input(shape=(32, 32, 3)),\n",
    "#     Conv2D(64, (5, 5), strides=(2, 2), padding='same', activation='relu'),\n",
    "#     BatchNormalization(),\n",
    "#     Conv2D(128, (5, 5), strides=(2, 2), padding='same', activation='relu'),\n",
    "#     BatchNormalization(),\n",
    "#     Flatten(),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# # Define the GAN model\n",
    "# gan_input = Input(shape=(100,))\n",
    "# x_gen = generator(gan_input)\n",
    "# gan_output = discriminator(x_gen)\n",
    "\n",
    "# # Define the GAN model\n",
    "# gan = Model(gan_input, gan_output)\n",
    "\n",
    "# # Compile the GAN model\n",
    "# gan.compile(loss=minimax_loss, optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "# # Train the GAN model\n",
    "# batch_size = 32\n",
    "# for epoch in range(100):\n",
    "#     for i in range(x_train.shape[0] // batch_size):\n",
    "#         # Sample a batch of real images\n",
    "#         idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "#         x_real = x_train[idx]\n",
    "\n",
    "#         # Sample a batch of random noise\n",
    "#         noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "#         # Generate fake images\n",
    "#         x_fake = generator.predict(noise)\n",
    "\n",
    "#         # Train the discriminator\n",
    "#         d_loss_real = discriminator.train_on_batch(x_real, np.ones((batch_size, 1)))\n",
    "#         d_loss_fake = discriminator.train_on_batch(x_fake, np.zeros((batch_size, 1)))\n",
    "#         d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "#         # Train the generator\n",
    "#         g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "#     # Print the loss at each epoch\n",
    "#     print(f'Epoch {epoch+1}, D loss: {d_loss[0]}, G loss: {g_loss}')\n",
    "# This code defines a GAN model that consists of a generator network and a discriminator network. The generator network takes a random noise vector as input and produces a synthetic image. The discriminator network takes an image as input and outputs a probability that the image is real.\n",
    "\n",
    "# The GAN model is trained using the minimax loss function, which is a combination of the discriminator loss and the generator loss. The discriminator loss is the binary cross-entropy loss between the predicted probabilities and the true labels (1 for real images and 0 for fake images). The generator loss is the binary cross-entropy loss between the predicted probabilities and the true labels (1 for fake images).\n",
    "\n",
    "# The GAN model is trained for 100 epochs, with a batch size of 32. At each epoch, the discriminator is trained on a batch of real images and a batch of fake images, and the generator is trained on a batch of random noise vectors.\n",
    "\n",
    "# Note that this is just an example code, and you may need to modify it to suit your specific needs. You can also try different architectures, hyperparameters, and training strategies to improve the performance of your GAN model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Transfer Learning with GANs on the CIFAR-10 Dataset\n",
    "# Transfer learning is commonly used to improve GAN performance. In this question, you should\n",
    "# implement a GAN for image generation using transfer learning. The data source is the CIFAR-10\n",
    "# dataset, which is a dataset of 60,000 32x32 color images in 10 different classes.\n",
    "\n",
    "# Here are the steps you should follow:\n",
    "# A Load a pre-trained convolutional neural network (CNN) model (e*g*, VGG16 or ResNet) using a library\n",
    "# like PyTorch or TensorFlow)\n",
    "# A Modify the model for GAN-based image generation by removing the fully connected layers)\n",
    "# A Implement a generator and discriminator network)\n",
    "# A Train the GAN using the pre-trained CNN as the feature extractor to improve the quality of generated\n",
    "# images\n",
    "# A Evaluate the performance of your GAN by generating sample images from random noise.\n",
    "# Answer :\n",
    "# Here is an example implementation of a GAN using transfer learning on the CIFAR-10 dataset:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications import VGG16\n",
    "# from tensorflow.keras.layers import Input, Conv2DTranspose, BatchNormalization, LeakyReLU\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# # Load the pre-trained VGG16 model\n",
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# # Freeze the layers of the pre-trained model\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# # Define the generator network\n",
    "# generator_input = Input(shape=(100,))\n",
    "# x = generator_input\n",
    "# x = Dense(8*8*128, activation='relu')(x)\n",
    "# x = Reshape((8, 8, 128))(x)\n",
    "# x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='tanh')(x)\n",
    "# generator = Model(generator_input, x)\n",
    "\n",
    "# # Define the discriminator network\n",
    "# discriminator_input = Input(shape=(32, 32, 3))\n",
    "# x = discriminator_input\n",
    "# x = base_model(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(1, activation='sigmoid')(x)\n",
    "# discriminator = Model(discriminator_input, x)\n",
    "\n",
    "# # Define the GAN model\n",
    "# gan_input = Input(shape=(100,))\n",
    "# x_gen = generator(gan_input)\n",
    "# gan_output = discriminator(x_gen)\n",
    "# gan = Model(gan_input, gan_output)\n",
    "\n",
    "# # Compile the GAN model\n",
    "# gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# # Train the GAN model\n",
    "# batch_size = 32\n",
    "# for epoch in range(100):\n",
    "#     for i in range(60000 // batch_size):\n",
    "#         # Sample a batch of random noise\n",
    "#         noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "#         # Generate fake images\n",
    "#         x_fake = generator.predict(noise)\n",
    "\n",
    "#         # Sample a batch of real images\n",
    "#         idx = np.random.randint(0, 60000, batch_size)\n",
    "#         x_real = cifar10_train_images[idx]\n",
    "\n",
    "#         # Train the discriminator\n",
    "#         d_loss_real = discriminator.train_on_batch(x_real, np.ones((batch_size, 1)))\n",
    "#         d_loss_fake = discriminator.train_on_batch(x_fake, np.zeros((batch_size, 1)))\n",
    "#         d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "#         # Train the generator\n",
    "#         g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "#     # Print the loss at each epoch\n",
    "#     print(f'Epoch {epoch+1}, D loss: {d_loss[0]}, G loss: {g_loss}')\n",
    "\n",
    "# # Evaluate the performance of the GAN by generating sample images\n",
    "# noise = np.random.normal(0, 1, (10, 100))\n",
    "# generated_images = generator.predict(noise)\n",
    "\n",
    "# # Display the generated images\n",
    "# for i in range(10):\n",
    "#     plt.imshow(generated_images[i], cmap='rgb')\n",
    "#     plt.show()\n",
    "# This code uses the pre-trained VGG16 model as the feature extractor for the discriminator network. The generator network is defined using a series of transposed convolutional layers to upsample the input noise vector to a 32x32 image. The GAN model is trained using the binary cross-entropy loss function, and the performance is evaluated by generating sample images from random noise.\n",
    "\n",
    "# Note that this is just an example implementation, and you may need to modify it to suit your specific needs. You can also try different architectures, hyperparameters, and training strategies to improve the performance of your GAN model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7* Can you create a Python function that implements a basic Generative Adversarial Network (GAN) for\n",
    "# generating grayscale images resembling handwritten digits (0 to 9) from the MNIST dataset? Your\n",
    "# function should include the generator and discriminator networks, as well as the training loop with\n",
    "# appropriate loss functions and optimizers* Additionally, demonstrates the generation of a few sample\n",
    "# images using the trained GAN model.\n",
    "# Answer :\n",
    "\n",
    "# Here is a Python function that implements a basic Generative Adversarial Network (GAN) for generating grayscale images resembling handwritten digits (0 to 9) from the MNIST dataset:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "# from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n",
    "# from tensorflow.keras.layers import BatchNormalization, LeakyReLU\n",
    "# from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "# from tensorflow.keras.models import Model\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def train_gan(latent_dim, epochs, batch_size):\n",
    "#     # Load MNIST dataset\n",
    "#     (x_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "#     # Rescale -1 to 1\n",
    "#     x_train = x_train.astype('float32') / 127.5 - 1.0\n",
    "#     x_train = np.expand_dims(x_train, axis=3)\n",
    "\n",
    "#     # Generator network\n",
    "#     generator_input = Input(shape=(latent_dim,))\n",
    "#     x = Dense(7*7*128, activation='relu')(generator_input)\n",
    "#     x = Reshape((7, 7, 128))(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU()(x)\n",
    "#     x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU()(x)\n",
    "#     x = Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh')(x)\n",
    "#     generator = Model(generator_input, x)\n",
    "\n",
    "#     # Discriminator network\n",
    "#     discriminator_input = Input(shape=(28, 28, 1))\n",
    "#     x = Conv2D(64, (5, 5), strides=(2, 2), padding='same')(discriminator_input)\n",
    "#     x = LeakyReLU()(x)\n",
    "#     x = Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "#     x = LeakyReLU()(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(1, activation='sigmoid')(x)\n",
    "#     discriminator = Model(discriminator_input, x)\n",
    "\n",
    "#     # GAN model\n",
    "#     gan_input = Input(shape=(latent_dim,))\n",
    "#     x_gen = generator(gan_input)\n",
    "#     gan_output = discriminator(x_gen)\n",
    "#     gan = Model(gan_input, gan_output)\n",
    "\n",
    "#     # Compile models\n",
    "#     discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "#     gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "#     # Train GAN\n",
    "#     for epoch in range(epochs):\n",
    "#         for i in range(x_train.shape[0] // batch_size):\n",
    "#             # Sample a batch of real images\n",
    "#             idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "#             x_real = x_train[idx]\n",
    "\n",
    "#             # Sample a batch of random noise\n",
    "#             noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "#             # Generate fake images\n",
    "#             x_fake = generator.predict(noise)\n",
    "\n",
    "#             # Train discriminator\n",
    "#             d_loss_real = discriminator.train_on_batch(x_real, np.ones((batch_size, 1)))\n",
    "#             d_loss_fake = discriminator.train_on_batch(x_fake, np.zeros((batch_size, 1)))\n",
    "#             d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "#             # Train generator\n",
    "#             g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "#         # Print loss at each epoch\n",
    "#         print(f'Epoch {epoch+1}, D loss: {d_loss[0]}, G loss: {g_loss}')\n",
    "\n",
    "#     # Generate sample images\n",
    "#     noise = np.random.normal(0, 1, (10, latent_dim))\n",
    "#     generated_images = generator.predict(noise)\n",
    "\n",
    "#     # Display generated images\n",
    "#     for i in range(10):\n",
    "#         plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "#         plt.show()\n",
    "\n",
    "# # Train GAN\n",
    "# train_gan(latent_dim=100, epochs=100, batch_size=32)\n",
    "# This function trains a basic GAN model to generate grayscale images resembling handwritten digits (0 to 9) from the MNIST dataset. The generator network takes a random noise vector as input and produces a 28x28 grayscale image. The discriminator network takes an image as input and outputs a probability that the image is real. The GAN model is trained using the binary cross-entropy loss function and the Adam optimizer.\n",
    "\n",
    "# After training the GAN model, the function generates a few sample images using the trained generator network and displays them using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8* Create a Deep Convolutional Generative Adversarial Network (DCGAN) in TensorFlow/Keras to\n",
    "# generate high-resolution images from low res images data set:\n",
    "# * Describe the\n",
    "# architectural choices you make and how they contribute to the model]s performance\n",
    "# Answer :\n",
    "# Here is an example of a Deep Convolutional Generative Adversarial Network (DCGAN) in TensorFlow/Keras to generate high-resolution images from low-resolution images:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# # Define the generator network\n",
    "# generator_input = Input(shape=(64, 64, 3))  # low-resolution image\n",
    "# x = Conv2D(64, (5, 5), strides=(2, 2), padding='same')(generator_input)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2D(256, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# generator_output = Conv2D(3, (5, 5), strides=(1, 1), padding='same', activation='tanh')(x)\n",
    "# generator = Model(generator_input, generator_output)\n",
    "\n",
    "# # Define the discriminator network\n",
    "# discriminator_input = Input(shape=(256, 256, 3))  # high-resolution image\n",
    "# x = Conv2D(64, (5, 5), strides=(2, 2), padding='same')(discriminator_input)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2D(256, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(1, activation='sigmoid')(x)\n",
    "# discriminator = Model(discriminator_input, x)\n",
    "\n",
    "# # Define the DCGAN model\n",
    "# dcgan_input = Input(shape=(64, 64, 3))  # low-resolution image\n",
    "# x_gen = generator(dcgan_input)\n",
    "# x_dis = discriminator(x_gen)\n",
    "# dcgan = Model(dcgan_input, x_dis)\n",
    "\n",
    "# # Compile the DCGAN model\n",
    "# dcgan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# # Train the DCGAN model\n",
    "# for epoch in range(100):\n",
    "#     for i in range(1000):\n",
    "#         # Sample a batch of low-resolution images\n",
    "#         low_res_images = ...\n",
    "\n",
    "#         # Sample a batch of high-resolution images\n",
    "#         high_res_images = ...\n",
    "\n",
    "#         # Train the generator\n",
    "#         g_loss = dcgan.train_on_batch(low_res_images, np.ones((batch_size, 1)))\n",
    "\n",
    "#         # Train the discriminator\n",
    "#         d_loss_real = discriminator.train_on_batch(high_res_images, np.ones((batch_size, 1)))\n",
    "#         d_loss_fake = discriminator.train_on_batch(generator.predict(low_res_images), np.zeros((batch_size, 1)))\n",
    "#         d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "#     # Print loss at each epoch\n",
    "#     print(f'Epoch {epoch+1}, G loss: {g_loss}, D loss: {d_loss}')\n",
    "# Architectural choices:\n",
    "\n",
    "# Generator network: The generator network consists of a series of convolutional and transposed convolutional layers to upsample the low-resolution image to a high-resolution image. The architecture is inspired by the U-Net architecture, which is commonly used for image-to-image translation tasks.\n",
    "# Discriminator network: The discriminator network consists of a series of convolutional layers to downsample the high-resolution image to a lower resolution, followed by a dense layer to output a probability that the image is real. The architecture is inspired by the VGG16 architecture, which is commonly used for image classification tasks.\n",
    "# Batch normalization: Batch normalization is used to normalize the input data for each layer, which helps to stabilize the training process and improve the performance of the model.\n",
    "# Leaky ReLU activation: Leaky ReLU activation is used to introduce non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Create a conditional GAN which can generate images based on input condition* The data set you\n",
    "# would use in this case is fashion_mnist dataset from tensorflow data sets.\n",
    "# Reference:\n",
    "# Answer :\n",
    "# Here is an example of a conditional GAN that generates images based on input conditions using the Fashion MNIST dataset:\n",
    "\n",
    "# python\n",
    "# Copy code\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.datasets import fashion_mnist\n",
    "# from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n",
    "# from tensorflow.keras.layers import BatchNormalization, LeakyReLU\n",
    "# from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# # Load Fashion MNIST dataset\n",
    "# (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# # Normalize input data\n",
    "# x_train = x_train.astype('float32') / 255.0\n",
    "# x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# # Define the generator network\n",
    "# generator_input = Input(shape=(10,))  # input condition (class label)\n",
    "# x = Dense(7*7*128, activation='relu')(generator_input)\n",
    "# x = Reshape((7, 7, 128))(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh')(x)\n",
    "# generator = Model(generator_input, x)\n",
    "\n",
    "# # Define the discriminator network\n",
    "# discriminator_input = Input(shape=(28, 28, 1))  # input image\n",
    "# x = Conv2D(64, (5, 5), strides=(2, 2), padding='same')(discriminator_input)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU()(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(1, activation='sigmoid')(x)\n",
    "# discriminator = Model(discriminator_input, x)\n",
    "\n",
    "# # Define the conditional GAN model\n",
    "# conditional_gan_input = Input(shape=(10,))  # input condition (class label)\n",
    "# x_gen = generator(conditional_gan_input)\n",
    "# x_dis = discriminator(x_gen)\n",
    "# conditional_gan = Model(conditional_gan_input, x_dis)\n",
    "\n",
    "# # Compile the conditional GAN model\n",
    "# conditional_gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# # Train the conditional GAN model\n",
    "# for epoch in range(100):\n",
    "#     for i in range(1000):\n",
    "#         # Sample a batch of input conditions (class labels)\n",
    "#         conditions = np.random.randint(0, 10, size=(32,))\n",
    "\n",
    "#         # Sample a batch of real images\n",
    "#         idx = np.random.randint(0, x_train.shape[0], size=(32,))\n",
    "#         real_images = x_train[idx]\n",
    "\n",
    "#         # Train the generator\n",
    "#         g_loss = conditional_gan.train_on_batch(conditions, np.ones((32, 1)))\n",
    "\n",
    "#         # Train the discriminator\n",
    "#         d_loss_real = discriminator.train_on_batch(real_images, np.ones((32, 1)))\n",
    "#         d_loss_fake = discriminator.train_on_batch(generator.predict(conditions), np.zeros((32, 1)))\n",
    "#         d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "#     # Print loss at each epoch\n",
    "#     print(f'Epoch {epoch+1}, G loss: {g_loss}, D loss: {d_loss}')\n",
    "\n",
    "# # Generate images based on input conditions\n",
    "# conditions = np.array([[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]])\n",
    "# generated_images = generator.predict(conditions)\n",
    "\n",
    "# # Display generated images\n",
    "# for i in range(10):\n",
    "#     plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "#     plt.title(f'Generated image for class {conditions[i, 0]}')\n",
    "#     plt.show()\n",
    "# In this example, the generator network takes a 10-dimensional input condition (class label) and generates a 28x28 grayscale image. The discriminator network takes a 28x28 grayscale image as input and outputs a probability that the image is real. The conditional GAN model is trained using the binary cross-entropy loss function and the Adam optimizer.\n",
    "\n",
    "# After training the conditional GAN model, we can generate images based on input conditions by passing the input conditions through the generator network. The generated images are displayed using Matplotlib.\n",
    "\n",
    "# Note that this is a basic example of a conditional GAN, and there are many ways to improve the architecture and training procedure to generate more realistic and diverse images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
